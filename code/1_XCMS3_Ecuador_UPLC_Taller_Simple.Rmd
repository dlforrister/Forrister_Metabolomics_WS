---
title: "XCMS3_Ecuador_Check"
author: "Dale Forrister"
date: "5/11/2020"
output: html_document
---
---
title: "XCMS_3_Example"
author: "Dale Forrister"
date: "5/11/2021"
output: html_document
---
## Install required packages

Note: This script is optimized for the latest R version (>3.6). Be sure to get
the most recent version of R before running. The code below installs the
required packages and all needed dependencies. Note: You don't have to run this
chunk if the packages are already installed.

```{r, eval = FALSE, message = FALSE}
if (!require(here)) {install.packages('here')}
library(here)
here::here()


```
This, sets there working directory for rmarkdown files. then you need to use here("relative_file_path") to access files. i.e. read.csv(here("./data/file1.csv"),row.names=1)

```{r, eval = FALSE, message = FALSE}
if(!requireNamespace("BiocManager")){
    install.packages("BiocManager")}
if(!require(xcms) | !require(CAMERA)){
BiocManager::install(c("xcms", "CAMERA")) }
if(!require(Spectra)){
BiocManager::install("Spectra")}


```

## Preprocess your data using XCMS3 and export data files for feature-based molecular networking through GNPS

To follow this example tutorial, download the folder named
*peak/AMG_Plant_subset* from:
[here](https://massive.ucsd.edu/ProteoSAFe/dataset.jsp?task=de2d18fd91804785bce8c225cc94a444)

Note that the settings for `xcms` used in this tutorial were not optimized,
specifically the alignment based on the default *obiwarp* parameters might
perform a little to strong retention time adjustment.
For more information on optimization of the parameters see the [xcms vignette](https://bioconductor.org/packages/release/bioc/vignettes/xcms/inst/doc/xcms.html)
or the [LC-MS data pre-processing with xcms](https://github.com/jorainer/metabolomics2018) workshop.

Load required libraries and utility functions for GNPS export.

```{r, message = FALSE}
library(xcms)
library(CAMERA)
source("https://raw.githubusercontent.com/jorainer/xcms-gnps-tools/master/customFunctions.R")
```

Use socket based parallel processing on Windows systems. The number (`4`)
defines the number of parallel tasks. Adapt this setting to the number of CPUs
available on your system. Also note that it is usually better to not use all
CPUs of a system as a) during the analysis the MS data has to be imported from
the original mzML/mzXML/CDF files and it will thus be limited by the I/O of the
hard disks and b) the computer needs to have enough memory to load the complete
MS data of as many raw data files than there are parallel jobs.

```{r}
detectCores()
if(.Platform$OS.type == "unix") {
  register(bpstart(MulticoreParam(30)))
} else {register(bpstart(SnowParam(3)))} 
```

### Load data

Load all *.mzXML* files and define sample grouping. Note that for this example
we assign all samples to the same group. This should be changed according to the
experimental setup.

```{r}
sample_meta <- read.csv(here("data","sample_metadata_all_samples_Oct_22.csv"))



#list all of the raw files. Not that when we converted we sometimes converted to .mzXML and ssomtimes .mzML. The latter is the prefered format but to keep it simple we load both files in.

mzXMLfiles <- list.files(path = here('data'),
                               pattern = ".mzXML", recursive = F)
mzMLfiles <- list.files(path = here('data'),
                               pattern = ".mzML", recursive = F)
all_files <- c(mzXMLfiles,mzMLfiles)

length(all_files)


all_files_sample <- data.frame(file = gsub('~/Documents_Mac/CODE_GIT_HUB_2017_Aug_31/Ecuador_XCMS_3_FBMN_github/data/',"",all_files))
all_files_sample$path <- unlist(all_files)
all_files_sample$sample_name <- gsub(".mzML","",all_files_sample$file)
all_files_sample$sample_name <- gsub(".mzXML","",all_files_sample$sample_name)


table(sample_meta$file_name.sample.id %in% all_files_sample$sample_name)
#there are no files from the meta data excel that did not make it into the actual files folder from the 10th of February.
#sample_meta$file_name.sample.id[!sample_meta$file_name.sample.id %in% all_files_sample$sample_name]
# now no files are missing

#what about the other way around. Are there files that are not in our sample metadata that are in the actual folder?

table(all_files_sample$sample_name %in% sample_meta$file_name.sample.id)
#at least for this subst there are no files missing.
#lots of files are missing from the database that are in the actual samples folder
#these are all files that need/ to be rerun
#all_files_sample$sample_name[!all_files_sample$sample_name %in% sample_meta$file_name.sample.id]

#lots of files are missing from the meta data....

#we can ignore this for the subset on feb 10th
#all_files <- all_files_sample$path[all_files_sample$sample_name %in% sample_meta$file_name.sample.id]
#all_files_sample_2 <- all_files_sample[all_files_sample$sample_name %in% sample_meta$file_name.sample.id,]
#all_files_sample_2 <- all_files_sample_2[match(sample_meta$file_name.sample.id,all_files_sample_2$sample_name),]

all_files_sample_2 <- all_files_sample
s_groups <- rep("unknown",length(all_files_sample_2$sample_name))

s_groups[which(grepl("BLK",all_files_sample_2$sample_name))] <- "Blank"
s_groups[which(grepl("ENE",all_files_sample_2$sample_name))] <- "Sample"
s_groups[which(grepl("RTI",all_files_sample_2$sample_name))] <- "Standard"



table(s_groups)
#remove unknowns from list and metadata

#all_files <- all_files[-which(s_groups == "unknown")]
#all_files_sample <- all_files_sample[-which(s_groups == "unknown"),]
#s_groups <- s_groups[-which(s_groups == "unknown")]




all_files <- all_files_sample_2$path

pheno <- data.frame(sample_name = all_files_sample_2$sample_name,
                    sample_group = s_groups, stringsAsFactors = FALSE)

nrow(pheno) == length(all_files)
pheno
```
Now we have a list of samples that we will run and the groups they belong to:

Blanks
Sample
Standard


```{r}
```

Read all raw data (which includes MS1 spectra only so we can use CAMERA).

```{r}
rawData <- readMSData(here("data",all_files), centroided. = TRUE,mode= "onDisk",
                pdata = new("NAnnotatedDataFrame", pheno))

rawData

```

### Peak picking

Define settings for the centWave peak detection. As mentioned in the
introduction, these settings should always be adapted to the analyzed data set.

```{r}
#cwp <- CentWaveParam(snthresh = 1, noise = 100, peakwidth = c(3, 30), ppm = 50)
#cwparam <- CentWaveParam(ppm=50, peakwidth=c(2,30), snthresh=5, prefilter=c(3,500),noise = 500)
#cwp <- CentWaveParam(ppm=15, peakwidth=c(3,30), snthresh=3, prefilter=c(3,5000))
```

Perform the chromatographic peak detection using *centWave*.

```{r, warning = FALSE, message = FALSE}

cwparam <- CentWaveParam(ppm=50, 
                         peakwidth=c(2,30), 
                         snthresh=5, 
                         prefilter=c(3,500),
                         noise = 500)
processedData <-  findChromPeaks(rawData, param = cwparam)



#save.image("~/Documents_Mac/CODE_GIT_HUB_2017_Aug_31/Ecuador_XCMS_3_FBMN_github/2021_8_01.RData")
```

Get an overview of the detected peaks, using a heatmap which represents the
number of peaks detected for each file along the retention time range.

```{r, fig.width = 10, fig.height = 6}
plotChromPeakImage(processedData, binSize = 20) 
```

### Retention time alignment

Do an *obiwarp*-based alignment using the default settings (ideally adapt
settings to the analyzed data set).

### We are going to use peak groups to group based on density instead because obiwarp is outdated,
### but first we are going to group the peaks found with the centwave param using the peakdensity param

```{r, message = FALSE, warning = FALSE}
dparam1 <- PeakDensityParam(sampleGroups = as.character(s_groups), bw=5, binSize=0.25, minSamples=1, minFraction = 0.001)
processedData <- groupChromPeaks(object = processedData, param = dparam1)

pgp <- PeakGroupsParam(minFraction= 0.001, extraPeaks = 100,smooth="loess", span = 1,  subset = which(pheno$sample_group =="Standard"),subsetAdjust = "previous")

processedData <- adjustRtime(processedData, param = pgp)


```

Plot the difference between adjusted and raw retention times.

```{r, fig.width = 12, fig.height = 6}
plotAdjustedRtime(processedData)
```


### Peak grouping
### you have to do peak grouping BEFORE retention time adjustment, and then again after

```{r, message = FALSE, warning = FALSE}
dparam2 <- PeakDensityParam(sampleGroups = as.character(s_groups), bw=10, binSize=0.1, minSamples=1, minFraction = 0.001)

processedData <- groupChromPeaks(object = processedData, param = dparam2)

```

### Gap filling

Fill-in missing peaks. Peak detection might have failed for some features in
some samples. The `fillChromPeaks` function allows to integrate for such cases
all signal in the respective m/z - retention time range. Below we first define
the median width of identified chromatographic peaks in retention time dimension
and use this as parameter `fixedRt` for the `fillChromPeaks`.

```{r, message = FALSE, warning = FALSE}
medWidth <- median(chromPeaks(processedData)[, "rtmax"] -
                   chromPeaks(processedData)[, "rtmin"])
## fill missing peaks

if(.Platform$OS.type == "unix") {
  register(bpstart(MulticoreParam(1)))
} else {register(bpstart(SnowParam(3)))} 

fp <- FillChromPeaksParam(expandMz = 0.25, expandRt = medWidth)
processedData <- fillChromPeaks(processedData, param = fp)


save.image(here("./data/image_after_fill_peaks.rdata"))
```
### Export data

#### export MS1 and MS2 features

Below we use the `featureSpectra` function to extract all MS2 spectra with their
precursor m/z being within the m/z range of a feature/peak and their retention
time within the rt range of the same feature/peak. Note that for older `xcms`
versions (i.e. before version 3.12) `return.type = "Spectra"` has to be used
instead of `return.type = "MSpectra"` as in the example below. Zero-intensity
values are removed from each spectrum with the `clean` function, and
subsequently processed into the expected format using the `formatSpectraForGNPS`
function.

```{r}
## export the individual spectra into a .mgf file


filteredMs2Spectra <- featureSpectra(processedData, return.type = "Spectra")
filteredMs2Spectra <- clean(filteredMs2Spectra, all = TRUE)
filteredMs2Spectra <- formatSpectraForGNPS(filteredMs2Spectra)

```
Export peak area quantification table. To this end we first extract the *feature
definitions* (i.e. the m/z and retention time ranges and other metadata for all
defined features in the data set) and then the integrated peak areas (with the
`featureValues` function). This peak area quantification table contains features
and respective per sample peak areas in columns. The combined data is then saved
to the file *xcms_all.txt*. Note that it is now also possible to use the entire
feature table in the FBMN workflow.

```{r}
## get feature definitions and intensities
featuresDef <- featureDefinitions(processedData)
featuresIntensities <- featureValues(processedData, value = "into")

## generate data table
dataTable <- merge(featuresDef, featuresIntensities, by = 0, all = TRUE)
dataTable <- dataTable[, !(colnames(dataTable) %in% c("peakidx"))]
```

```{r}
head(dataTable)
```




The extracted MS2 spectra are saved as *ms2spectra_all.mgf* file. This file can
for example be used to do *in silico* structure prediction through
[SIRIUS+CSI:FingerID](https://bio.informatik.uni-jena.de/software/sirius/).

```{r}
writeMgfData(filteredMs2Spectra, here("results","ms2spectra_all.mgf"))
```

Export peak area quantification table. To this end we first extract the *feature
definitions* (i.e. the m/z and retention time ranges and other metadata for all
defined features in the data set) and then the integrated peak areas (with the
`featureValues` function). This peak area quantification table contains features
and respective per sample peak areas in columns. The combined data is then saved
to the file *xcms_all.txt*. Note that it is now also possible to use the entire
feature table in the FBMN workflow.

```{r}
## get feature names

featuresDef <- featureDefinitions(processedData)
featuresIntensities <- featureValues(processedData, value = "into")
## generate data table
feat_table <- merge(featuresDef, featuresIntensities, by = 0, all = TRUE)
feat_table <- feat_table[, !(colnames(feat_table) %in% c("peakidx"))]
feat_table


```

### Inspect xcms object and find rows (features) that are within 0.01 Da and 30 sec of one another


```{r}

feat_table$ID.matches <- apply(outer(feat_table$mzmed,   feat_table$mzmed,   function(x, y) abs(x - y) <   0.01) &
                       outer(feat_table$rtmed,   feat_table$rtmed,   function(x, y) abs(x - y) <   30) &
                       diag(nrow(feat_table)) == 0, 
                       MARGIN = 1,
                       function(x) paste(row.names(feat_table)[x], collapse = ", "))


feat_table_match <- feat_table[feat_table$ID.matches=="",]
feat_table_match

```

```{r}
write.table(feat_table_match, here("results","xcms_all.txt"), sep = "\t", quote = FALSE, 
            row.names = FALSE)
```


### CAMERA annotation of adducts and isotopes

The code in this section describes how the data can be processed to enable the
ion identify networking (IIN) in FBMN. In brief, we are using the `CAMERA`
package to determine which features might be adducts or isotopes of the same
compound. This information is exported as an additional *edges* file and is
added to the feature annotation..

Note: the CAMERA package supports objects of class `xcmsSet`, which were the
outputs of the *old* version of xcms. The newer `XCMSnExp` object can however be
converted to an `xcmsSet` object with the `as(object, "xcmsSet")`, which does
however not support conversion of objects with MS level > 1 data. Thus we use
the `filterMsLevel` function on the result object to restrict the data in the
object to MS level 1 prior to the conversion.

```{r, message = FALSE}
library(CAMERA)
xset <- as(filterMsLevel(processedData, msLevel = 1L), "xcmsSet")
sampclass(xset) <- s_groups
  
# peak grouping and annotation
xsa <- xsAnnotate(xs=xset, polarity="negative")
```

The following worflow can be divided in 2 big steps: (1) feature grouping into 
*pseudospectras* and (2) annotate the ion species.

The first step has the aim to group the chromatographic peaks from the same
metabolite (but for potentially different adducts/ions of it). We thus first
group peaks of the `xsAnnotate` object (`xsa`) with a similar retention time
(i.e. co-eluting peaks). Parameter `perfwhm` allows to define the percentage of
the width of the FWHM (full width at half maximum). For data sets with a higher
variation in retention times this values should be increased.

```{r}
xsaF <- groupFWHM(xsa, sigma = 6, perfwhm=0.6)
```

In this example, this step has generated 373 pseudospectra.

Then, we verify/clean-up the peak grouping by correlating the peak shape of
features clustered in the same pseudospectra group (in order to separate
                                                    co-eluting metabolites). Peaks with correlations lower than `cor_eic_th` are
separated into different groups. Parameters `calcCiS`, `calcCaS` and `calcIso`
allow to specify whether correlations should be performed within the same sample
(the default), across samples or whether isotope detection information should be
included for graph clustering. We use the default values here, but this should
be adapted to the respective experimental setup (e.g. setting `calcSaS = TRUE`
                                                 if it can be assumed that the same adducts are generated across all samples in
                                                 the data set).

```{r, message = FALSE}
xsaC <- groupCorr(xsaF, cor_eic_th = 0.5, pval = 0.05, graphMethod = "hcs",
                  calcCiS = TRUE, calcCaS = TRUE, calcIso = FALSE)
```

This step has seperated our 373 pseudospectra into 1301

Now we are going to deal with the second big step of CAMERA workflow: annotation
of isotopes and adducts within pseudospectra-groups. The `findIsotopes`
annotates isotopes according to the relation between features'
C12/C13. Parameter `intval` allows to specify which feature value should be uses
(`"into"` for the maximum peak intensity, `"into"` for the integrated peak
intensity and `"intb"` for the baseline corrected integrated peak intensity,
which might not be available for all peak detection methods). Parameters
`maxcharge` and `maxiso` allow to specify the maximal number of isotope charge
and isotope peaks, respectively.

```{r, message = FALSE}

xsaFI <- findIsotopes(xsaC, maxcharge = 2, maxiso = 3, minfrac = 0.4,
                      ppm=20, mzabs=0.05,intval="intb")

```

Next adducts are identified and annotated based on the m/z differences between
grouped chromatographic peaks. Setting the correct polarity with parameter
`polarity` (either `"positive"` or `"negative"` is key). For potential adducts,
`CAMERA` calculates by default all possible combinations from the standard ions
depending on the ionization mode. Alternatively it is possible to limit to a
predefined set of adducts with the `rules` parameter.

```{r, message = FALSE}
rule_mod<-read.csv(file=here("current_neg_extended_adducts_v16.csv"), header= TRUE)
  
xsaFA <- findAdducts(xsaFI, polarity="negative", rules = rule_mod, 
                     max_peaks = 100, multiplier = 3, ppm = 20, mzabs=0.05)
```

Sometimes CAMERA is grouping features of different co-eluting metabolites. It
might be helpful to evaluate whether peaks from the same group have different
peak shapes. Parameter `pspec` allows to specify from which group (column
`"pcgroup"`) the data should be plotted.

```{r, message = FALSE}
plotEICs(xsaFA, maxlabel = 5, pspec = 3)
```


Next we extract the *edge list* from the `CAMERA` result object with the
`getEdgelist` function (defined in
[xcms-gnps-tools](https://github.com/jorainer/xcms-gnps-tools)).

```{r}
edgelist <- getEdgelist(xsaFA)
```

The resulting `data.frame` contains an edge between nodes (i.e. pairwise
associations between potential adducts/isotopes from the same *correlation
group* defined by `CAMERA`) in each row. All edges fulfill the criteria from
`CAMERA` (i.e. representing signal from co-eluting ions with a similar peak
shape), but only for few the actual adduct annotation could be determined (see
below).

```{r}
edgelist[1:8, ]
```

For features that are adducts or isotopes of the same compound the edge table
contains the value `"MS1 annotation"` in column `"EdgeType"`. This information
can be used to e.g. subset the edges table to contain only edges for features
with adduct or isotope annotations. Below we show the first 6 edges with such
annotation.

```{r}
head(edgelist[edgelist$EdgeType == "MS1 annotation", ])
```

In addition we extract per-feature annotations from the `CAMERA` result object
with the `getFeatureAnnotations` function (also defined in
[xcms-gnps-tools](https://github.com/jorainer/xcms-gnps-tools)). These are
appended to the feature table `dataTable` generated in the previous section.

```{r message = FALSE}
camera_feature_ann <- getFeatureAnnotations(xsaFA)
feat_table <- cbind(feat_table, camera_feature_ann)
```

At last we export the edgelist containing all edges with adduct or isotope
annotation to the file *camera_iin_edgelist.csv* and the feature annotation and
quantification table to *xcms_all.txt*. These can be used as input for the Ion
Identity Networking (IIN) in GNPS.

```{r}
edgelist_sub <- edgelist[edgelist$Annotation != "", ]
write.csv(edgelist_sub, file = here("results","camera_iin_edgelist.csv"), row.names = FALSE,
          quote = FALSE, na = "")

write.table(dataTable, file = here("results","xcms_all.txt"),
            row.names = FALSE, quote = FALSE, sep = "\t", na = "")
```


```{r}
xset5 <- feat_table_match
# END OF XCMS AND CAMERA CODE

xset5[is.na(xset5)] <- 0
  
xset6 <- xset5
names(xset6)[which(startsWith(names(xset6),"X"))] <- pheno$sample_name
xset6


ftbl <- xset6

```

#Start filtering features we don't want to keep. 

```{r}


#remove any features with TIC < 500 after filled features.
ftbl[,startsWith(names(ftbl),c("ENE","BLK","RTI"))] <- replace(ftbl[,startsWith(names(ftbl),c("ENE","BLK","RTI"))], ftbl[,startsWith(names(ftbl),c("ENE","BLK","RTI"))] <= 500, 0)

ftbl_1 <- ftbl[rowSums(ftbl[,startsWith(names(ftbl),c("ENE","BLK","RTI"))]) > 0,]

#Remove any compounds found in the blank (Average TIC in samples has to be 2X the average TIC in blanks)
ftbl_1$TIC_Average <- rowMeans(replace(ftbl_1[,startsWith(names(ftbl_1),"ENE")], ftbl_1[,startsWith(names(ftbl_1),"ENE")] == 0, NA), na.rm = TRUE)

ftbl_1$TIC_Average_blank <- rowMeans(replace(ftbl_1[,startsWith(names(ftbl_1),"BLK")], ftbl_1[,startsWith(names(ftbl_1),"BLK")] == 0, NA), na.rm = TRUE)

ftbl_1$TIC_Average_blank[is.na(ftbl_1$TIC_Average_blank)] <- 0

ftbl_2 <- ftbl_1[ftbl_1$TIC_Average > 2*ftbl_1$TIC_Average_blank,c(1:12,100:102,which(startsWith(names(ftbl_1),c("ENE","RTI"))))]

names(featuretab)

```
Write feature table for upload to GNPS. 
```{r}
names(ftbl_2)


write.table(feat_table_final, here("results","xcms_ms1_feat.txt"), sep = "\t", quote = FALSE, 
            row.names = FALSE)

write.csv(feat_table_final,here("results","xcms_ms1_feat.csv"))


```


### Session information

```{r}
sessionInfo()
```
